---
layout: page
title: Literature
permalink: /literature/
---

# Literature 

## Kavi

1. J. Kim, S. Kim, J. Kong and S. Yoon, "Glow-TTS: A Generative Flow for Text-to-Speech via Monotonic Alignment Search," arXiv:2005.11129v2  [eess.AS], Oct. 2020. [Online]. Available: https://arxiv.org/pdf/2005.11129.pdf

2. D. S. Park, W. Chan, Y. Zhang, C.-C. Chiu, B. Zoph, E. D. Cubuk, and Q. V. Le, “SpecAugment: A simple data augmentation method for automatic speech,”  in Interspeech 2019.ISCA, Sep. 2019. [Online]. Available:  https://doi.org/10.21437/interspeech.2019-2680

3. Y. Hwang, H. Cho, H. Yang, D.-O. Won, I. Oh, and S.-W. Lee, “Mel-spectrogram augmentation for sequence to sequence voice conversion,” Jun. 2020. [Online]. Available: https://arxiv.org/pdf/2001.01401.pdf

4. K. Ito and L. Johnson, "The LJ Speech Dataset", Keithito.com, 2017 [Online]. Available: https://keithito.com/LJ-Speech-Dataset/.

## Jiajun

### Speech Animation Methods (including Dataset) Review

* Deep Person Generation: A Survey from the Perspective of Face, Pose and Cloth Synthesis (https://arxiv.org/abs/2109.02081)

* What comprises a good talking-head video generation?: A Survey and Benchmark (https://arxiv.org/abs/2005.03201)

### Emotional Speech Animation

* Audio-driven emotional video portraits (https://arxiv.org/abs/2104.07452)

* Write-a-speaker: Text-based Emotional and Rhythmic Talking-head Generation (https://arxiv.org/abs/2104.07995)

## Xiaoxiao

## Ruibin
